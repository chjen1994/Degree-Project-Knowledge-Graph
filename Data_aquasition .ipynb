
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning approach:\n",
    "\n",
    "#First identify the table of content by regex to get mention of \"Item\" in <Table> <tbody> tag(perhaps extract the table of content)\n",
    "#or search <a href=\"#.....\" util the mention of Item16, signautre\n",
    "#extract all the href in <a> attribute in the table of content (ex. href1, href2, href3 …)\n",
    "\n",
    "#Second have algorithm to identify <a name=\"href1\"> and save the content between href1 and href2, href2 and href3, …\n",
    "\n",
    "#Third, clean the html tags in the contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_html(path):\n",
    "    return BeautifulSoup(open(path), 'html.parser')\n",
    "\n",
    "def soup_get_text(soup):\n",
    "    print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First extract the location of the table of content \n",
    "# use regex to identify Signature/Item 16 and get everything above\n",
    "#only works with the text and items in table of content contains href#if only in the page number, doesn't work\n",
    "\n",
    "def remove_duplicates_in_list(List):\n",
    "    return list(dict.fromkeys(List))\n",
    "def get_table_of_content_links1(soup):\n",
    "    tag = soup.find('a',string=re.compile(\"Financial Statement Schedules\"))\n",
    "    tag_item = soup.find('a',string=re.compile(\"Item 15\"))\n",
    "    if tag==None and tag_item!=None:\n",
    "        tag = tag_item\n",
    "    \n",
    "    links = list()\n",
    "    links.append(tag.get('href')[1:])\n",
    "    for elements in tag.previous_elements:\n",
    "        if elements.name=='a' and elements.has_attr('href') and elements.get('href')[0]=='#':\n",
    "            #print(elements)\n",
    "            links.append(elements.get('href')[1:])\n",
    "    \n",
    "    links.reverse()\n",
    "    return remove_duplicates_in_list(links)\n",
    "    #print_list(links)\n",
    "\n",
    "#\n",
    "def get_table_of_content_links2(soup):\n",
    "    links = list()\n",
    "    for link in soup.find_all('a'):\n",
    "    #link.get('href')\n",
    "    #print(link.get('href'))\n",
    "    #print(link.get('name'))\n",
    "        if link.get('href')!=None and link.get('href')[0]=='#':\n",
    "            links.append(link.get('href')[1:])\n",
    "    return links\n",
    "# or identify the signature link and use find_previous method to extract:extract()?\n",
    "\n",
    "def print_list(lists):\n",
    "    for list in lists:\n",
    "        print(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unable to format tables\n",
    "def get_all_sections(sections, links):\n",
    "    for i in range(len(links)):\n",
    "        if i<len(links)-1:\n",
    "            sections.append(get_section(links[i],links[i+1]))\n",
    "        else:\n",
    "            sections.append(get_last_section(links[i]))\n",
    "\n",
    "def get_section(link1, link2):#need to add \"id\"\n",
    "    section_str=\"\"\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.has_attr('name') and link['name']==link1:\n",
    "            for elements in link.next_elements:\n",
    "                if elements.name=='a' and elements.has_attr('name') and elements['name']==link2:\n",
    "                    break \n",
    "                if str(elements)[0] != '<':\n",
    "                    section_str = section_str + str(elements)\n",
    "                    #print(repr(elements))\n",
    "            #Sections = Sections + str(elements)\n",
    "            break\n",
    "        elif link.has_attr('id') and link['id']==link1:\n",
    "            for elements in link.next_elements:\n",
    "                if elements.name=='a' and elements.has_attr('id') and elements['id']==link2:\n",
    "                    break \n",
    "                if str(elements)[0] != '<':\n",
    "                    section_str = section_str + str(elements)\n",
    "                    #print(repr(elements))\n",
    "            #Sections = Sections + str(elements)\n",
    "            break\n",
    "    return section_str\n",
    "\n",
    "def get_last_section(link1):\n",
    "    section_str=\"\"\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.has_attr('name') and link['name']==link1:\n",
    "            for elements in link.next_elements:\n",
    "                if str(elements)[0] != '<':\n",
    "                    section_str = section_str + str(elements)\n",
    "                    #print(repr(elements))\n",
    "            #Sections = Sections + str(elements)\n",
    "            break\n",
    "        elif link.has_attr('id') and link['id']==link1:\n",
    "            for elements in link.next_elements:\n",
    "                if str(elements)[0] != '<':\n",
    "                    section_str = section_str + str(elements)\n",
    "                    #print(repr(elements))\n",
    "            #Sections = Sections + str(elements)\n",
    "            break\n",
    "    return section_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT_1_path=\"/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/MSFT/10-K/0001564590-19-027952.txt\"\n",
    "MSFT_2_path=\"/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/MSFT/10-K/0001564590-18-019062.txt\"\n",
    "APPL_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/AAPL/10-K/0000320193-19-000119.txt'\n",
    "APPL_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/AAPL/10-K/0000320193-18-000145.txt'\n",
    "VISA_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/V/10-K/0001403161-18-000055.txt'\n",
    "VISA_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/V/10-K/0001403161-19-000050.txt'\n",
    "GOOG_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/GOOG/10-K/0001652044-19-000004.txt'\n",
    "GOOG_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/GOOG/10-K/0001652044-20-000008.txt'\n",
    "BLK_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/BLK/10-K/0001564590-19-005479.txt'\n",
    "BLK_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/BLK/10-K/0001564590-20-007807.txt'\n",
    "BA_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/BA/10-K/0000012927-19-000010.txt'\n",
    "BA_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/BA/10-K/0000012927-20-000014.txt'\n",
    "FORD_1_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/F/10-K/0000037996-20-000010.txt'\n",
    "FORD_2_path='/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/F/10-K/0000037996-19-000012.txt'\n",
    "\n",
    "soup=load_html(MSFT_1_path)\n",
    "#soup_get_text(soup)\n",
    "#visa, msft, goog, blk work\n",
    "#, ba_1_path uses <a id=\"links\">\n",
    "#ford dont work cuz href is at the page number in toc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM_1_BUSINESS\n",
      "EXECUTIVE_FICERS__REGISTRANT\n",
      "ITEM_1A_RISK_FACTORS\n",
      "ITEM_1B_UNRESOLVED_STAFF_COMMENTS\n",
      "ITEM_2_PROPERTIES\n",
      "ITEM_3_LEGAL_PROCEEDINGS\n",
      "ITEM_4_MINE_SAFETY_DISCLOSURES\n",
      "ITEM5_MARKET_FOR_REGISTRANTS\n",
      "ITEM_6_SELECTED_FINANCIAL_DATA\n",
      "ITEM_7_MANAGEMENTS_DISCUSSION_ANALYSIS_F\n",
      "ITEM_7A_QUANTITATIVE_QUALITATIVE_DISCLOS\n",
      "ITEM_8_FINANCIAL_STATEMENTS_AND_SUPPLEM\n",
      "ITEM_9_CHANGES_IN_DISAGREEMENTS_WITH_ACC\n",
      "ITEM_9A_CONTROLS_PROCEDURES\n",
      "REPORT_MANAGEMENT_ON_INTERNAL_CONTROL_OV\n",
      "REPORT_INDEPENDENT_REGISTERED_PUBLIC_ACC\n",
      "ITEM_9B_OR_INFORMATION\n",
      "ITEM_10_DIRECTORS_EXECUTIVE_FICERS_CORPO\n",
      "ITEM_11_EXECUTIVE_COMPENSATION\n",
      "ITEM_12_SECURITY_OWNERSHIP_CERTAIN_BENEF\n",
      "ITEM_13_CERTAIN_RELATIONSHIPS_RELATED_TR\n",
      "ITEM_14_PRINCIPAL_ACCOUNTING_FEES_SERVIC\n",
      "ITEM_15_EXHIBITS_FINANCIAL_STATEMENT_SCH\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "links = get_table_of_content_links1(soup)\n",
    "print_list(links)\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections=list()\n",
    "get_all_sections(sections,links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTIVE OFFICERS OF THE REGISTRANT\n",
      "Our executive officers as of July 31, 2019 were as follows:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name\n",
      "\n",
      " \n",
      "\n",
      "Age\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Position with the Company\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Satya Nadella\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "51\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Chief Executive Officer\n",
      "\n",
      "\n",
      "\n",
      "Christopher C. Capossela\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "49\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Executive Vice President, Marketing and Consumer Business, and Chief Marketing Officer\n",
      "\n",
      "\n",
      "\n",
      "Jean-Philippe Courtois\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "58\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Executive Vice President and President, Microsoft Global Sales, Marketing and Operations\n",
      "\n",
      "\n",
      "\n",
      "Kathleen T. Hogan\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "53\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Executive Vice President, Human Resources\n",
      "\n",
      "\n",
      "\n",
      "Amy E. Hood\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "47\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Executive Vice President, Chief Financial Officer\n",
      "\n",
      "\n",
      "\n",
      "Margaret L. Johnson\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "57\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Executive Vice President, Business Development\n",
      "\n",
      "\n",
      "\n",
      "Bradford L. Smith\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "60\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "President and Chief Legal Officer\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Mr. Nadella was appointed Chief Executive Officer in February 2014. He served as Executive Vice President, Cloud and Enterprise from July 2013 until that time. From 2011 to 2013, Mr. Nadella served as President, Server and Tools. From 2009 to 2011, he was Senior Vice President, Online Services Division. From 2008 to 2009, he was Senior Vice President, Search, Portal, and Advertising. Since joining Microsoft in 1992, Mr. Nadella’s roles also included Vice President of the Business Division. Mr. Nadella also serves on the Board of Directors of Starbucks Corporation.\n",
      "Mr. Capossela was appointed Executive Vice President, Marketing and Consumer Business, and Chief Marketing Officer in July 2016. He had served as Executive Vice President, Chief Marketing Officer since March 2014. Previously, he served as the worldwide leader of the Consumer Channels Group, responsible for sales and marketing activities with OEMs, operators, and retail partners. In his more than 25 years at Microsoft, Mr. Capossela has held a variety of marketing leadership roles in the Microsoft Office Division. He was responsible for marketing productivity solutions including Microsoft Office, Office 365, SharePoint, Exchange, Skype for Business, Project, and Visio.\n",
      "Mr. Courtois was appointed Executive Vice President and President, Microsoft Global Sales, Marketing and Operations in July 2016. Before that he was President of Microsoft International since 2005. He was Chief Executive Officer, Microsoft Europe, Middle East, and Africa from 2003 to 2005. He was Senior Vice President and President, Microsoft Europe, Middle East, and Africa from 2000 to 2003. He was Corporate Vice President, Worldwide Customer Marketing from 1998 to 2000. Mr. Courtois joined Microsoft in 1984.\n",
      "Ms. Hogan was appointed Executive Vice President, Human Resources in November 2014. Prior to that Ms. Hogan was Corporate Vice President of Microsoft Services. She also served as Corporate Vice President of Customer Service and Support. Ms. Hogan joined Microsoft in 2003.\n",
      "Ms. Hood was appointed Executive Vice President and Chief Financial Officer in July 2013, subsequent to her appointment as Chief Financial Officer in May 2013. From 2010 to 2013, Ms. Hood was Chief Financial Officer of the Microsoft Business Division. From 2006 through 2009, Ms. Hood was General Manager, Microsoft Business Division Strategy. Since joining Microsoft in 2002, Ms. Hood has also held finance-related positions in the Server and Tools Business and the corporate finance organization. Ms. Hood also serves on the Board of Directors of 3M Corporation.\n",
      "Ms. Johnson was appointed Executive Vice President, Business Development in September 2014. Prior to that Ms. Johnson spent 24 years at Qualcomm in various leadership positions across engineering, sales, marketing and business development. She most recently served as Executive Vice President of Qualcomm Technologies, Inc. Ms. Johnson also serves on the Board of Directors of BlackRock, Inc.\n",
      "Mr. Smith was appointed President and Chief Legal Officer in September 2015. He served as Executive Vice President, General Counsel, and Secretary from 2011 to 2015, and served as Senior Vice President, General Counsel, and Secretary from 2001 to 2011. Mr. Smith was also named Chief Compliance Officer in 2002. Since joining Microsoft in 1993, he was Deputy General Counsel for Worldwide Sales and previously was responsible for managing the European Law and Corporate Affairs Group, based in Paris. Mr. Smith also serves on the Board of Directors of Netflix, Inc.\n",
      "15\n",
      "\n",
      "PART I\n",
      "Item 1\n",
      " \n",
      "EMPLOYEES\n",
      "As of June 30, 2019, we employed approximately 144,000 people on a full-time basis, 85,000 in the U.S. and 59,000 internationally. Of the total employed people, 47,000 were in operations, including manufacturing, distribution, product support, and consulting services; 47,000 were in product research and development; 38,000 were in sales and marketing; and 12,000 were in general and administration. Certain of our employees are subject to collective bargaining agreements.\n",
      "AVAILABLE INFORMATION\n",
      "Our Internet address is www.microsoft.com. At our Investor Relations website, www.microsoft.com/investor, we make available free of charge a variety of information for investors. Our goal is to maintain the Investor Relations website as a portal through which investors can easily find or navigate to pertinent information about us, including:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Our annual report on Form 10-K, quarterly reports on Form 10-Q, current reports on Form 8-K, and any amendments to those reports, as soon as reasonably practicable after we electronically file that material with or furnish it to the Securities and Exchange Commission (“SEC”) at www.sec.gov.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Information on our business strategies, financial results, and metrics for investors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Announcements of investor conferences, speeches, and events at which our executives talk about our product, service, and competitive strategies. Archives of these events are also available.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Press releases on quarterly earnings, product and service announcements, legal developments, and international news.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Corporate governance information including our articles of incorporation, bylaws, governance guidelines, committee charters, codes of conduct and ethics, global corporate social responsibility initiatives, and other governance-related policies.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Other news and announcements that we may post from time to time that investors might find useful or interesting.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "•\n",
      "\n",
      "Opportunities to sign up for email alerts to have information pushed in real time.\n",
      "The information found on our website is not part of this or any other report we file with, or furnish to, the SEC. In addition to these channels, we use social media to communicate to the public. It is possible that the information we post on social media could be deemed to be material to investors. We encourage investors, the media, and others interested in Microsoft to review the information we post on the social media channels listed on our Investor Relations website.\n",
      " \n",
      " \n",
      " \n",
      "16\n",
      "\n",
      "PART I\n",
      "Item 1A\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sections[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#get table of content\\n\\n\"identify the mention of Signatures\"\\ntag = soup.find(\\'a\\',string=re.compile(\"Signatures\"))\\n#print(tag)\\nlinks = list()\\nfor elements in tag.previous_elements:\\n    if elements.name==\\'a\\' and elements.has_attr(\\'href\\') and elements.get(\\'href\\')[0]==\\'#\\':\\n        #print(elements)\\n        links.append(elements.get(\\'href\\')[1:])\\n        \\nlinks.reverse()\\n#print_list(links)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#get table of content\n",
    "\n",
    "\"identify the mention of Signatures\"\n",
    "tag = soup.find('a',string=re.compile(\"Signatures\"))\n",
    "#print(tag)\n",
    "links = list()\n",
    "for elements in tag.previous_elements:\n",
    "    if elements.name=='a' and elements.has_attr('href') and elements.get('href')[0]=='#':\n",
    "        #print(elements)\n",
    "        links.append(elements.get('href')[1:])\n",
    "        \n",
    "links.reverse()\n",
    "#print_list(links)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsoup = BeautifulSoup(open(\"/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/MSFT/10-K/0001564590-19-027952.txt\"), \\'html.parser\\')\\n#print(soup.prettify())\\nprint(soup.get_text())\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the html\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(open(\"/Users/davidren/Desktop/Education/KTH/2019-2020/2020 Spring/Master Thesis/Data/sec_edgar_filings/MSFT/10-K/0001564590-19-027952.txt\"), 'html.parser')\n",
    "#print(soup.prettify())\n",
    "print(soup.get_text())\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#get all href from the table of content \\nLinks = list()\\nfor link in soup.find_all('a'):\\n    #link.get('href')\\n    #print(link.get('href'))\\n    #print(link.get('name'))\\n    if link.get('href')!=None and link.get('href')[0]=='#':\\n        Links.append(link.get('href')[1:])\\nfor link in Links:\\n    print(link)\\n        \\n    #remove the '#' and store them in a list\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#get all href from the table of content \n",
    "Links = list()\n",
    "for link in soup.find_all('a'):\n",
    "    #link.get('href')\n",
    "    #print(link.get('href'))\n",
    "    #print(link.get('name'))\n",
    "    if link.get('href')!=None and link.get('href')[0]=='#':\n",
    "        Links.append(link.get('href')[1:])\n",
    "for link in Links:\n",
    "    print(link)\n",
    "        \n",
    "    #remove the '#' and store them in a list\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSections=\"\"\\nfor link in soup.find_all(\\'a\\'):\\n    if link.has_attr(\\'name\\') and link[\\'name\\']==\\'ITEM_1_BUSINESS\\':\\n        for elements in link.next_elements:\\n            if elements.name==\\'a\\' and elements.has_attr(\\'name\\') and elements[\\'name\\']==\\'ITEM_1B_UNRESOLVED_STAFF_COMMENTS\\':\\n                break\\n                \\n            \\n            if str(elements)[0] != \\'<\\':\\n                Sections = Sections + str(elements)\\n                print(repr(elements))\\n            #Sections = Sections + str(elements)\\n            \\n        break\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get section \n",
    "#example get section between Item 1 and Item 1A\n",
    "\n",
    "#Problem also get the sentences\n",
    "\"\"\"\n",
    "Sections=\"\"\n",
    "for link in soup.find_all('a'):\n",
    "    if link.has_attr('name') and link['name']=='ITEM_1_BUSINESS':\n",
    "        for elements in link.next_elements:\n",
    "            if elements.name=='a' and elements.has_attr('name') and elements['name']=='ITEM_1B_UNRESOLVED_STAFF_COMMENTS':\n",
    "                break\n",
    "                \n",
    "            \n",
    "            if str(elements)[0] != '<':\n",
    "                Sections = Sections + str(elements)\n",
    "                print(repr(elements))\n",
    "            #Sections = Sections + str(elements)\n",
    "            \n",
    "        break\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
